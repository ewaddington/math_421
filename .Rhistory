# LDA
# Linear Discriminant Analysis categorizes data into groups by finding a linear combination of variables.
library(caret)
library(tidyverse)
library(MASS)
df = read_csv("water_potability.csv")
df= df %>%  rename(target = Potability)
model = lda(target ~ Hardness + ph,
data = df)
pred = predict(model, df,
type = 'response')$class
cm <- confusionMatrix(data = pred, reference = factor(df$target))
cm$overall[1]
d = data.frame(pred = pred, obs = factor(df$target))
library(yardstick)
d %>% conf_mat(pred, obs) %>% autoplot
# QDA
# Quadratic Discriminant Analysis is an extension of LDA, however it does not use a linear model, therefore it is capable of providing a better fit to the data.
model = qda(target ~ Hardness + ph,
data = df)
pred = predict(model, df,
type = 'response')$class
cm <- confusionMatrix(data = pred, reference = factor(df$target))
cm$overall[1]
# Modeling w/ Numeric Targets
# Linear Regression
# Linear Regression estimates the linear model between the target variable and the explanatory variables.
df = read.csv("water_potability.csv")
df = df %>%
dplyr::select(Solids, Hardness, ph, Sulfate, Chloramines, Organic_carbon) %>%
rename(target = Hardness) %>%
drop_na()
my_linear_model <- lm(target ~ ., data = df)
summary(my_linear_model)
my_linear_model <- lm(target ~., data = df)
summary(my_linear_model)
# PCA Regression
# Principal Component Analysis used in regression is used for estimating explanatory variables in a linear regression model.
res.pca <- prcomp(df_pca,  scale = TRUE)
library(tidyverse)
library(caret)
df = read_csv('water_potability')
library(tidyverse)
library(caret)
# Select variables for modeling
df = df %>%
select(Potability, ph, Hardness, Sulfates) %>%
drop_na()
library(tidyverse)
library(caret)
df = read_csv('water_potability.csv')
# Select variables for modeling
df = df %>%
select(Potability, ph, Hardness, Sulfates) %>%
drop_na()
# Select variables for modeling
df = df %>% select(Potability, ph, Hardness, Sulfates) %>%
drop_na()
# LDA
# Linear Discriminant Analysis categorizes data into groups by finding a linear combination of variables.
library(caret)
library(tidyverse)
library(MASS)
df = read_csv("water_potability.csv")
df= df %>%  rename(target = Potability)
model = lda(target ~ Hardness + ph,
data = df)
pred = predict(model, df,
type = 'response')$class
cm <- confusionMatrix(data = pred, reference = factor(df$target))
cm$overall[1]
d = data.frame(pred = pred, obs = factor(df$target))
library(yardstick)
d %>% conf_mat(pred, obs) %>% autoplot
# QDA
# Quadratic Discriminant Analysis is an extension of LDA, however it does not use a linear model, therefore it is capable of providing a better fit to the data.
model = qda(target ~ Hardness + ph,
data = df)
pred = predict(model, df,
type = 'response')$class
cm <- confusionMatrix(data = pred, reference = factor(df$target))
cm$overall[1]
d = data.frame(pred = pred, obs = factor(df$target))
library(yardstick)
d %>% conf_mat(pred, obs) %>% autoplot
# Modeling w/ Numeric Targets
# Linear Regression
# Linear Regression estimates the linear model between the target variable and the explanatory variables.
df = read.csv("water_potability.csv")
df = df %>%
dplyr::select(Solids, Hardness, ph, Sulfate, Chloramines, Organic_carbon) %>%
rename(target = Hardness) %>%
drop_na()
my_linear_model <- lm(target ~ ., data = df)
summary(my_linear_model)
my_linear_model <- lm(target ~., data = df)
summary(my_linear_model)
# PCA Regression
# Principal Component Analysis used in regression is used for estimating explanatory variables in a linear regression model.
res.pca <- prcomp(df_pca,  scale = TRUE)
get_eig(res.pca)
# PCA Regression
# Principal Component Analysis used in regression is used for estimating explanatory variables in a linear regression model.
df_pca = df %>% dplyr::select(-target)
res.pca <- prcomp(df_pca,  scale = TRUE)
df2 = as_tibble(res.pca$x[, c(1:2)])
df2$target = df$target
df = df2
model = lm(target~., data = df)
summary(model)
# GLM Poisson Regression
# Poisson regression uses a generalized linear model to create a Poisson distribution to model the target variable using explanitory variables.
model = glm(target ~. ,
data = df,
family = poisson(link = "log"))
r2 = with(summary(model), 1 - deviance/null.deviance)
print(paste0("R-Squared: ", r2))
predict(model,
list(Hardness = 15, ph = 4),
type = 'response')
# Goodness-of-fit test
gof.pvalue = 1 - pchisq(model$deviance, model$df.residual)
gof.pvalue
knitr::opts_chunk$set(message = FALSE, eval = FALSE)
df$month2 <- case_when(
df$monthday <= 10 ~ 'early_month',
df$monthday <= 20 ~ 'mid_month',
TRUE ~ 'end_month'
)
install.packages('tidyverse')
install.packages("tidyverse")
library(tidyverse)
setwd("C:/Users/student/Desktop/New folder/math_421")
df <-  read.csv('all-states-history.csv')
library(lubridate)
df$month = month(df$date)
# day of the week
df$weekday = wday(df$date)
# day of the month
df$monthday <- mday(df$date)
df$daily_death <- case_when(
df$deathIncrease <3 ~ 'low',
df$deathIncrease <=14 ~ 'medium',
TRUE ~ 'high'
)
df$month2 <- case_when(
df$monthday <= 10 ~ 'early_month',
df$monthday <= 20 ~ 'mid_month',
TRUE ~ 'end_month'
)
df$weekend <- case_when(
df$weekday < 1 ~ 'weekend'
df$weekday <= 7 ~ 1
df$month2 <- case_when(
df$monthday <= 10 ~ 'early_month',
df$monthday <= 20 ~ 'mid_month',
TRUE ~ 'end_month'
)
df$weekend <- case_when(
df$weekday < 1
df$weekday <= 7 ~ 1
df$month2 <- case_when(
df$monthday <= 10 ~ 'early_month',
df$monthday <= 20 ~ 'mid_month',
TRUE ~ 'end_month'
)
df$weekend <- case_when(
df$weekday == 1 | df$weekday == 7 ~ 1,
TRUE ~ 0
)
df$month2 <- case_when(
df$monthday <= 10 ~ 'early_month',
df$monthday <= 20 ~ 'mid_month',
TRUE ~ 'end_month'
)
df$weekend <- case_when(
df$weekday == 1
df$weekday == 7 ~ 1,
df$month2 <- case_when(
df$monthday <= 10 ~ 'early_month',
df$monthday <= 20 ~ 'mid_month',
TRUE ~ 'end_month'
)
df$weekend <- case_when(
df$weekday == 1 | df$weekday == 7 ~ 1,
TRUE ~ 0
)
df <- df %>% select(-totalTestsViral)
x <- c(1:10)
# square root of x
sqrt(x)
sum(sqrt(x))
log(sum(sqrt(x)))
# log base 2 of 16
log(16, 2)
c(1:10) %>%
sqrt() %>%
sum() %>%
log() %>%
log(base = 2)
df %>%
group_by(weekday) %>%
summarise(mean(positiveIncrease))
df %>%
group_by(month) %>%
summarise(median_cases = median(positiveIncrease, na.rm = TRUE))
df %>%
group_by(month2) %>%
summarise(avg_cases = mean(positiveIncrease, na.rm = TRUE))
df %>%
group_by(weekend) %>%
summarise(median_cases = median(positiveIncrease, na.rm = TRUE))
df %>%
filter(month==1|month==2) %>%
group_by(month) %>%
summarise(positve_increase = mean(positiveIncrease))
df %>%
filter(month == 10 | month == 11, year(date) == 2020, weekend == 1) %>%
group_by(month) %>%
summarise(median_cases = median(positiveIncrease, na.rm = TRUE))
df %>%
filter(month %in% c(9, 10, 11), year(date) == 2020) %>%
group_by(month2) %>%
summarise(avg_deaths = mean(deathIncrease, na.rm = TRUE))
df %>%
filter(month %in% c(6, 7, 8), year(date) == 2020) %>%
group_by(weekend) %>%
summarise(avg_hospitalizations = mean(hospitalizedIncrease, na.rm = TRUE))
read_csv('us-states.csv')
setwd("C:/Users/student/Desktop/New folder/math_421")
df <-  read.csv('us-states.csv')
df$weekdays <- weekdays(df$Date)
setwd("C:/Users/student/Desktop/New folder/math_421")
df <-  read.csv('us-states.csv')
library(tidyverse)
library(lubridate)
df %>%
filter(state == "Rhode Island", year(date) == 2021) %>%
mutate(weekday = wday(date, label = TRUE)) %>%
group_by(weekday) %>%
summarise(median_cases = median(cases, na.rm = TRUE))
df %>%
filter(state == "Rhode Island", year(date) == 2021, month(date) %in% c(6, 7, 8, 9)) %>%
mutate(month = month(date, label = TRUE)) %>%
group_by(month) %>%
summarise(median_cases = median(cases, na.rm = TRUE))
df %>%
filter(weekend == 1) %>%
group_by(month) %>%
summarise(total_deaths = sum(deathIncrease, na.rm = TRUE)) %>%
arrange(desc(total_deaths))
df %>%
filter(weekend == 1) %>%
group_by(month) %>%
summarise(total_deaths = sum(deathIncrease, na.rm = TRUE)) %>%
arrange(desc(total_deaths))
df %>%
filter('weekend' == 1) %>%
group_by(month) %>%
summarise(total_deaths = sum(deathIncrease, na.rm = TRUE)) %>%
arrange(desc(total_deaths))
df %>%
filter('weekend' == 1) %>%
group_by('month') %>%
summarise(total_deaths = sum(deathIncrease, na.rm = TRUE)) %>%
arrange(desc(total_deaths))
setwd("C:/Users/student/Desktop/New folder/math_421")
df <-  read.csv('all-states-history.csv')
df %>%
filter('weekend' == 1) %>%
group_by('month') %>%
summarise(total_deaths = sum(deathIncrease, na.rm = TRUE)) %>%
arrange(desc(total_deaths))
read_csv('titanic.csv')
setwd("C:/Users/student/Desktop/New folder/math_421")
read_csv('titanic.csv')
setwd("C:/Users/student/Desktop/New folder/math_421")
read_csv('titanic.csv')
df_titanic <- titanic_data %>%
select(Sex, Age, Survived) %>%
mutate(AgeGroup = case_when(
Age <= 18 ~ 'Child',
Age > 18 ~ 'Adult'
))
setwd("C:/Users/student/Desktop/New folder/math_421")
read_csv('titanic.csv')
df_titanic <- 'titanic.csv' %>%
select(Sex, Age, Survived) %>%
mutate(AgeGroup = case_when(
Age <= 18 ~ 'Child',
Age > 18 ~ 'Adult'
))
setwd("C:/Users/student/Desktop/New folder/math_421")
df_titanic <- read_csv('titanic.csv')
setwd("C:/Users/student/Desktop/New folder/math_421")
df_titanic <- read_csv('titanic.csv')
df_titanic_selected <- df_titanic %>%
select(Survived, Pclass, Sex)
setwd("C:/Users/student/Desktop/New folder/math_421")
df_titanic <- read_csv('titanic.csv')
df_titanic_selected <- df_titanic %>%
select(Survived, Pclass, Sex)
df_titanic_survived <- df_titanic %>%
filter(Survived == 1)
df_titanic <- df_titanic %>%
mutate(AgeGroup = case_when(
Age <= 18 ~ 'Child',
Age > 18 ~ 'Adult',
TRUE ~ 'Unknown'
))
setwd("C:/Users/student/Desktop/New folder/math_421")
df_titanic <- read_csv('titanic.csv')
df_titanic_selected <- df_titanic %>%
select(Survived, Pclass, Sex)
df_titanic_survived <- df_titanic %>%
filter(Survived == 1)
df_titanic <- df_titanic %>%
mutate(AgeGroup = case_when(
Age <= 18 ~ 'Child',
Age > 18 ~ 'Adult',
TRUE ~ 'Unknown'
))
df_titanic %>%
summarise(avg_fare = mean(Fare, na.rm = TRUE))
setwd("C:/Users/student/Desktop/New folder/math_421")
df_titanic <- read_csv('titanic.csv')
df_titanic_selected <- df_titanic %>%
select(Survived, Pclass, Sex)
df_titanic_survived <- df_titanic %>%
filter(Survived == 1)
df_titanic <- df_titanic %>%
mutate(AgeGroup = case_when(
Age <= 18 ~ 'Child',
Age > 18 ~ 'Adult',
TRUE ~ 'Unknown'
))
df_titanic %>%
summarise(avg_fare = mean(Fare, na.rm = TRUE))
df_titanic %>%
arrange(desc(Fare))
df_titanic %>%
count(Pclass)
df_titanic %>%
count(Pclass) %>%
arrange(desc(n))
df_titanic %>%
filter(Survived == 1) %>%
count(Pclass) %>%
arrange(desc(n))
df_titanic %>%
group_by(Sex) %>%
summarise(avg_fare = mean(Fare, na.rm = TRUE))
df_titanic %>%
filter(Survived == 1) %>%
group_by(Pclass) %>%
summarise(avg_fare = mean(Fare, na.rm = TRUE))
setwd("C:/Users/student/Desktop/New folder/math_421")
df_titanic <- read_csv('titanic.csv')
df_titanic_selected <- df_titanic %>%
select(Survived, Pclass, Sex)
df_titanic_survived <- df_titanic %>%
filter(Survived == 1)
df_titanic <- df_titanic %>%
mutate(AgeGroup = case_when(
Age <= 18 ~ 'Child',
Age > 18 ~ 'Adult',
TRUE ~ 'Unknown'
))
df_titanic %>%
summarise(avg_fare = mean(Fare, na.rm = TRUE))
df_titanic %>%
arrange(desc(Fare))
df_titanic %>%
count(Pclass)
df_titanic %>%
count(Pclass) %>%
arrange(desc(n))
df_titanic %>%
filter(Survived == 1) %>%
count(Pclass) %>%
arrange(desc(n))
df_titanic %>%
group_by(Sex) %>%
summarise(avg_fare = mean(Fare, na.rm = TRUE))
df_titanic %>%
filter(Survived == 1) %>%
group_by(Pclass) %>%
summarise(avg_fare = mean(Fare, na.rm = TRUE))
df_titanic %>%
filter(Survived == 1) %>%
group_by(Pclass) %>%
summarise(avg_fare = mean(Fare, na.rm = TRUE)) %>%
arrange(desc(avg_fare))
setwd("C:/Users/student/Desktop/New folder/math_421")
knitr::opts_chunk$set(message = FALSE)
setwd("C:/Users/student/Desktop/New folder/math_421")
read_csv(adult_census_missing.csv)
setwd("C:/Users/student/Desktop/New folder/math_421")
read_csv('adult_census_missing.csv')
setwd("C:/Users/student/Desktop/New folder/math_421")
library(tidyverse)
df <- read_csv('adult_census_missing.csv')
df %>% summarise(mean_age=mean(Age, na.rm=TRUE))
setwd("C:/Users/student/Desktop/New folder/math_421")
library(tidyverse)
df <- read_csv('adult_census_missing.csv')
setwd("C:/Users/student/Desktop/New folder/math_421")
library(tidyverse)
df <- read_csv('adult_census_missing.csv')
colSums(is.na(df))
setwd("C:/Users/student/Desktop/New folder/math_421")
library(tidyverse)
df <- read_csv('adult_census_missing.csv')
colSums(is.na(df))
colMeans(is.na(df))
library(VIM)
install.packages(VIM)
library(VIM)
install.packages('VIM')
library(VIM)
df <- read_csv('adult_census_missing.csv')
df <- replace(df, df == 'Unknown' |
df == 'Missing' |
df == 'Not Available', NA)
install.packages('VIM')
library(VIM)
df <- read_csv('adult_census_missing.csv')
df <- replace(df, df == 'Unknown' |
df == 'Missing' |
df == 'Not Available', NA)
aggr(df)
install.packages("VIM")
install.packages('VIM')
library(VIM)
df <- read_csv('adult_census_missing.csv')
df <- replace(df, df == 'Unknown' |
df == 'Missing' |
df == 'Not Available', NA)
aggr(df)
colSums(df=='Missing', na.rm = TRUE)
df <- replace(df, df == 'Unknown' |
df == 'Missing' |
df == 'Not Available', NA)
install.packages('VIM')
library(VIM)
aggr(df)
colSums(df=='Missing', na.rm = TRUE)
df <- replace(df, df == 'Unknown' |
df == 'Missing' |
df == 'Not Available', NA)
library(VIM)
aggr(df)
colSums(df=='Missing', na.rm = TRUE)
df <- replace(df, df == 'Unknown' |
df == 'Missing' |
df == 'Not Available', NA)
library(VIM)
aggr(df)
setwd("C:/Users/student/Desktop/New folder/math_421")
library(tidyverse)
df <- read_csv('adult_census_missing.csv')
colSums(is.na(df))
colMeans(is.na(df))
install.packages('VIM')
library(VIM)
aggr(df)
colMeans(is.na(df))
colSums(df=='Missing', na.rm = TRUE)
df <- replace(df, df == 'Unknown' |
df == 'Missing' |
df == 'Not Available', NA)
drop_na(df)
colSums(df=='Missing', na.rm = TRUE)
df <- replace(df, df == 'Unknown' |
df == 'Missing' |
df == 'Not Available', NA)
drop_na(df)
drop_na(df, age, sex)
colSums(df=='Missing', na.rm = TRUE)
df <- replace(df, df == 'Unknown' |
df == 'Missing' |
df == 'Not Available', NA)
drop_na(df)
drop_na(df, age, sex)
df %>% select(-Age, -Sex)
colSums(df=='Missing', na.rm = TRUE)
df <- replace(df, df == 'Unknown' |
df == 'Missing' |
df == 'Not Available', NA)
drop_na(df)
drop_na(df, age, sex)
df %>% select(-age, -sex)
df %>% fill(df, .direction = 'updown')
df %>% fill(age, sex, .direction = 'updown')
colSums(df=='Missing', na.rm = TRUE)
df <- replace(df, df == 'Unknown' |
df == 'Missing' |
df == 'Not Available', NA)
drop_na(df)
drop_na(df, age, workclass)
df %>% select(-age, -workclass)
df %>% fill(age, workclass, .direction = 'updown')
mean_age <- mean(df$age, na.rm=TRUE)
df$age <- replace_na(df$age, mean_age)
mean_age <- mean(df$age, na.rm=TRUE)
df$age <- replace_na(df$age, mean_age)
majority_workclass <- names(which.max(table(df$workclass)))
df$workclass <- replace_na(df$workclass, majority_workclass)
setwd("C:/Users/student/Desktop/New folder/math_421")
install.packages('VIM')
library(VIM)
aggr(df)
